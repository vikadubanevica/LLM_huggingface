{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXv6aeWoQc-4",
        "outputId": "40d091bf-f798-44bf-d452-50a3618cb7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "pZyKzc9oQ9Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHAN_HtERI1W",
        "outputId": "fd01c88e-ba8e-4619-85ff-6217fbe82f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (4.67.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (5.29.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[sentencepiece]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[sentencepiece]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[sentencepiece]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[sentencepiece]) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using transformers.\n",
        "\n",
        "---\n",
        "Behind the pipelines\n"
      ],
      "metadata": {
        "id": "1RQsGSJqLHvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "        \"Great place to work!\"\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiB4nh1RGV70",
        "outputId": "8f0df4cf-a86f-4d3e-96e9-30aceab9b39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455},\n",
              " {'label': 'POSITIVE', 'score': 0.9998779296875}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(\"input IDs and attention masks: \\n \", inputs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl8q3UZbGWRt",
        "outputId": "40802d07-f590-402c-aa37-66ac06b7f10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input IDs and attention masks: \n",
            "  {'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)\n",
        "print(\"Hidden size: The vector dimension of each model input: \\n\", outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4X3QxxCHuJi",
        "outputId": "d76c60d1-c6a7-453b-d8e5-6efd0f9a493d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden size: The vector dimension of each model input: \n",
            " torch.Size([2, 16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)\n",
        "print(\"tensore shape: \\n\", outputs.logits.shape)\n",
        "print(\"unnormalized scores or logits: \\n\", outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZALHkFleGWaD",
        "outputId": "c312821d-ea92-461d-e302-d34ccf75ab10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensore shape: \n",
            " torch.Size([2, 2])\n",
            "unnormalized scores or logits: \n",
            " tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(\"predictions (-02 means zeros before first digit 0.0): \\n\", predictions)\n",
        "print(\"labels: \\n\", model.config.id2label)\n",
        "# model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pRxcg0SGWh2",
        "outputId": "65cf89eb-d17c-4695-8bf9-29ac496cfb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions (-02 means zeros before first digit 0.0): \n",
            " tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "labels: \n",
            " {0: 'NEGATIVE', 1: 'POSITIVE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Tokenizers\n"
      ],
      "metadata": {
        "id": "lWhw3_CZQ6Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "sequence = \"Using a Transformer network is simple\"#[\"I’ve been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-wg1rTSGWuD",
        "outputId": "a5bbb9c2-766a-49f8-84b8-5b84286722ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
            "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Handling multiple sequences"
      ],
      "metadata": {
        "id": "Nx4Txs9vWrOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# input_ids = torch.tensor([ids])\n",
        "# print(\"Input IDs:\", input_ids)\n",
        "\n",
        "batched_ids = [ids, ids]\n",
        "batched_ids = torch.tensor(batched_ids)\n",
        "print(\"Input IDs:\", batched_ids)\n",
        "\n",
        "\n",
        "# output = model(input_ids)\n",
        "# print(\"Logits:\", output.logits)\n",
        "\n",
        "output = model(batched_ids)\n",
        "print(\"Logits:\", output.logits)\n",
        "\n",
        "# obtain the same logits as before (but twice):"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFAammNfWuAa",
        "outputId": "4e8df8b4-cfba-4b40-c44a-816ce5d0ee90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012],\n",
            "        [ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789],\n",
            "        [-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Apply the tokenization manually on the two sentences used in section 2\n",
        "(“I’ve been waiting for a HuggingFace course my whole life.” and “I hate this so much!”).\n",
        "Pass them through the model and check that you get the same logits as in section 2.\n",
        "\n",
        "Now batch them together using the padding token,\n",
        "then create the proper attention mask.\n",
        "Check that you obtain the same results when going through the model!\"\"\""
      ],
      "metadata": {
        "id": "X8DxuKcjY9Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8x4Y8_YMY-ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "sequence2 = \"I hate this so much!\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "sequence_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens2 = tokenizer.tokenize(sequence2)\n",
        "sequence2_ids = tokenizer.convert_tokens_to_ids(tokens2)\n",
        "print(\"sequence: \", model(torch.tensor([sequence_ids])).logits)\n",
        "print(\"sequence2: \", model(torch.tensor([sequence2_ids])).logits)\n",
        "\n",
        "# Corrected batched_ids and padding\n",
        "max_length = max(len(sequence_ids), len(sequence2_ids))\n",
        "batched_ids = [\n",
        "    sequence_ids + [tokenizer.pad_token_id] * (max_length - len(sequence_ids)),\n",
        "    sequence2_ids + [tokenizer.pad_token_id] * (max_length - len(sequence2_ids)),\n",
        "]\n",
        "\n",
        "# Create attention mask\n",
        "attention_mask = [\n",
        "    [1] * len(sequence_ids) + [0] * (max_length - len(sequence_ids)),\n",
        "    [1] * len(sequence2_ids) + [0] * (max_length - len(sequence2_ids)),\n",
        "]\n",
        "print(\"attention_mask:\", attention_mask)\n",
        "\n",
        "# Pass batched_ids and attention mask to the model\n",
        "inputs = {\"input_ids\": torch.tensor(batched_ids), \"attention_mask\": torch.tensor(attention_mask)}\n",
        "print(\"batch:\", model(**inputs).logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb947206-91b4-4ee7-f533-aae1ae6b2260",
        "id": "cF1a6jrNZUHh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence:  tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n",
            "sequence2:  tensor([[ 3.1931, -2.6685]], grad_fn=<AddmmBackward0>)\n",
            "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "batch: tensor([[-2.7276,  2.8789],\n",
            "        [ 3.1931, -2.6685]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "output = model(**tokens)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iExT-rR0fqML",
        "outputId": "3d21d120-27b0-4ea0-ae2f-9f19ed42fe0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  2061,  2031,  1045,   999,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
            "        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Finetuning pretrained model\n",
        "---\n",
        "Processing the data\n"
      ],
      "metadata": {
        "id": "Hfkng5IE_JU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoncWuq9_Wf5",
        "outputId": "d1a520aa-bee0-4204-e688-fdc2eb56b3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR2Vbi_6_jhZ",
        "outputId": "bceb7bad-e3e7-4649-9bcd-fb53c36f8b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': 'Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .',\n",
              " 'sentence2': 'Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .',\n",
              " 'label': 0,\n",
              " 'idx': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zne8QFd8_yc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_val_dataset = raw_datasets[\"validation\"]\n",
        "raw_val_dataset[87]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4675e7f3-882f-4cae-8f8b-94820bef796d",
        "id": "INeL5zMq_ytR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': 'However , EPA officials would not confirm the 20 percent figure .',\n",
              " 'sentence2': 'Only in the past few weeks have officials settled on the 20 percent figure .',\n",
              " 'label': 0,\n",
              " 'idx': 812}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenized_sentences_1 = tokenizer(raw_train_dataset[\"sentence1\"][0])\n",
        "tokenized_sentences_2 = tokenizer(raw_train_dataset[\"sentence2\"][0])\n",
        "tokenized_sentences_1, tokenized_sentences_2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZBtAvxRAZip",
        "outputId": "999c8e1e-187a-4090-c138-347bb9f2b2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_ids': [101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
              " {'input_ids': [101, 7727, 2000, 2032, 2004, 2069, 1000, 1996, 7409, 1000, 1010, 2572, 3217, 5831, 5496, 2010, 2567, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .\", \"Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzIldQQrAtqJ",
        "outputId": "406c7204-5f28-461a-ba07-7cb915a28ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 24049, 2001, 2087, 3728, 3026, 3580, 2343, 2005, 1996, 9722, 1004, 4132, 9340, 12439, 2964, 2449, 1012, 102, 3026, 3580, 2343, 4388, 24049, 1010, 3839, 2132, 1997, 1996, 9722, 1998, 4132, 9340, 12439, 2964, 3131, 1010, 2097, 2599, 1996, 2047, 9178, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replicate the preprocessing on the GLUE SST-2 dataset. It’s a little bit different since it’s composed of single sentences instead of pairs, but the rest of what we did should look the same. For a harder challenge, try to write a preprocessing function that works on any of the GLUE tasks."
      ],
      "metadata": {
        "id": "1k9aq5VOGpYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DownloadConfig, disable_progress_bar\n",
        "\n",
        "disable_progress_bar()\n",
        "download_config = DownloadConfig(disable_tqdm=True)\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\", download_config=download_config)"
      ],
      "metadata": {
        "id": "4uy3PA3_GqRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuNHB6UBbOvo",
        "outputId": "c1f36588-25d8-470c-81bb-d80763d9e307"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIhBPunEIArf",
        "outputId": "d4fb8582-5b0a-4091-938a-b47c1b815295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'the greatest musicians ', 'label': 1, 'idx': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenized_sentences_1 = tokenizer(raw_train_dataset[\"sentence\"][0])\n",
        "tokenized_sentences_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft1e3zmIINQn",
        "outputId": "28096c56-e56f-4c53-b6c8-f8ed9dd2cd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences_2 = tokenizer(raw_train_dataset[\"sentence\"][1])\n",
        "tokenized_sentences_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cjvB7ZvR4B1",
        "outputId": "25d19878-4629-486f-89fd-4b6097914ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 3397, 2053, 15966, 1010, 2069, 4450, 2098, 18201, 2015, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True)\n",
        "\n",
        "  # changed the output from 'return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)'\n",
        "  # as dataset has only one sentence, no pairs"
      ],
      "metadata": {
        "id": "B0HDleupJpf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "id": "91eWDVKxJpus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79a9db9-93b5-48d4-f2a5-9912d7aec7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence\"]}\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-5vpexjRX1p",
        "outputId": "e075ef64-785b-4f91-9725-3013a0746610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 11, 15, 10, 22, 13, 29, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator(samples)\n",
        "{k: v.shape for k, v in batch.items()}\n",
        "#  8 samples with padding of 29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZYXkEbdV1GB",
        "outputId": "5d5df53e-75a8-4fde-9639-76b346260dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 29]),\n",
              " 'token_type_ids': torch.Size([8, 29]),\n",
              " 'attention_mask': torch.Size([8, 29]),\n",
              " 'labels': torch.Size([8])}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "Y8aZ8JO9Xr0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "# argument you have to provide is a directory where the trained model will be saved\n",
        "training_args = TrainingArguments(\"test-trainer\")"
      ],
      "metadata": {
        "id": "Pl7XuI8MXtOY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4ynOzIuXxCP",
        "outputId": "90d50ddd-2897-4b03-8eb8-f7f5d09b3f2e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "sNXTy1ONYCQK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "LiR-k56BYh9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jWNgtVXFbH8d",
        "outputId": "bdfe5baf-076c-479b-ab8f-c0f82aec04f3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(408, 2) (408,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "OHG2y_r5bq2e"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855d2627"
      },
      "source": [
        "# !pip install evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")"
      ],
      "metadata": {
        "id": "I-hk_3Jgbz1s"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6-KPdVyjsKO",
        "outputId": "2ffba0b8-6d38-4d46-ef0e-24cf83b90f07"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8504901960784313, 'f1': 0.8964346349745331}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "CNwmDPz_cNYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\"test-trainer\", eval_strategy=\"epoch\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "5SgVUoLGciEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full training and eval loop from scratch with modern PyTorch best practices\n",
        "\n",
        "# data loading\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from tqdm.auto import tqdm # Import tqdm\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# preprocess data before training\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names\n",
        "\n",
        "# define data loaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "# training with accelerator\n",
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
        "\n",
        "accelerator = Accelerator()\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
        "    train_dataloader, eval_dataloader, model, optimizer\n",
        ")\n",
        "\n",
        "# scheduler\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dl)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "# accessing GPU/TPU\n",
        "# import torch # This import is already at the top\n",
        "\n",
        "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# model.to(device) # This is handled by accelerator.prepare\n",
        "# device\n",
        "\n",
        "# train\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dl:\n",
        "        # batch = {k: v.to(device) for k, v in batch.items()} # This is handled by accelerator.prepare\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ND0RV-o4kFyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "import evaluate\n",
        "import torch\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "model.eval()\n",
        "for batch in eval_dl: # Use eval_dl prepared by accelerator\n",
        "    batch = {k: v.to(accelerator.device) for k, v in batch.items()} # Use accelerator.device\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEVo6kDVcL6X",
        "outputId": "2eb4200a-4017-489b-c992-317f1ef98451"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8529411764705882, 'f1': 0.8951048951048951}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 module - about pushing models and creating repos on Hugginface.\n",
        "---\n",
        "Not interested trying.\n"
      ],
      "metadata": {
        "id": "ToyakKG78csX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 module\n",
        "---\n",
        "Downloading datasets from anywhere\n"
      ],
      "metadata": {
        "id": "lcfj-ELs8kDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "url = \"https://github.com/crux82/squad-it/raw/master/\"\n",
        "data_files = {\n",
        "    \"train\": url + \"SQuAD_it-train.json.gz\",\n",
        "    \"test\": url + \"SQuAD_it-test.json.gz\",\n",
        "}\n",
        "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")"
      ],
      "metadata": {
        "id": "uBYOjAku8psQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
        "!unzip drugsCom_raw.zip\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\n",
        "# \\t is the tab character in Python\n",
        "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")\n",
        "\n",
        "drug_sample = drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "# Peek at the first few examples\n"
      ],
      "metadata": {
        "id": "wTjqtXtR-YBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee54211-ae09-4b66-d826-a3c55cda0b87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-20 17:36:27--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘drugsCom_raw.zip.1’\n",
            "\n",
            "drugsCom_raw.zip.1      [   <=>              ]  41.00M  87.8MB/s    in 0.5s    \n",
            "\n",
            "2026-01-20 17:36:28 (87.8 MB/s) - ‘drugsCom_raw.zip.1’ saved [42989872]\n",
            "\n",
            "Archive:  drugsCom_raw.zip\n",
            "replace drugsComTest_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "replace drugsComTrain_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_sample[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q01cTKmciOc",
        "outputId": "7a5b23f6-4627-4f80-8182-933b54bb1b95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0': [87571, 178045, 80482],\n",
              " 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],\n",
              " 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],\n",
              " 'review': ['\"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!\"',\n",
              "  '\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"',\n",
              "  '\"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.\"'],\n",
              " 'rating': [9.0, 3.0, 10.0],\n",
              " 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],\n",
              " 'usefulCount': [36, 13, 128]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in drug_dataset.keys():\n",
        "    assert len(drug_dataset[split]) == len(drug_dataset[split].unique(\"drugName\"))"
      ],
      "metadata": {
        "id": "FRTg1z97-ugA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71f59234",
        "outputId": "c66c1097-db2b-4000-d5d4-a6c501dad8e1"
      },
      "source": [
        "print(\"Unique drug names in training set:\", len(drug_dataset[\"train\"].unique(\"drugName\")))\n",
        "print(\"Unique drug names in test set:\", len(drug_dataset[\"test\"].unique(\"drugName\")))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique drug names in training set: 3436\n",
            "Unique drug names in test set: 2637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in drug_dataset.keys():\n",
        "    print(len(drug_dataset[\"train\"].unique(\"condition\")))"
      ],
      "metadata": {
        "id": "SkYJ1qJg_dDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3e3972-7ba9-4008-e871-a7fd0667bc73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "885\n",
            "885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_dataset = drug_dataset.rename_column(\n",
        "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\"\n",
        ")\n",
        "drug_dataset"
      ],
      "metadata": {
        "id": "ryGwvkkI-_dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6305301c-9c8a-4ca8-b945-6009b3457101"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
              "        num_rows: 161297\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
              "        num_rows: 53766\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def filter_nones(x):\n",
        "#     return x[\"condition\"] is not None\n",
        "# drug_dataset.filter(filter_nones)\n",
        "\n",
        "# or\n",
        "\n",
        "drug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)"
      ],
      "metadata": {
        "id": "6_Z9HRNU_tvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase_condition(example):\n",
        "    return {\"condition\": example[\"condition\"].lower()}\n",
        "\n",
        "\n",
        "drug_dataset.map(lowercase_condition)"
      ],
      "metadata": {
        "id": "nXDfj6sh_lEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f929afac-f306-45ba-9a90-9bcdec99d468"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
              "        num_rows: 160398\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
              "        num_rows: 53471\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_review_length(example):\n",
        "    return {\"review_length\": len(example[\"review\"].split())}\n",
        "drug_dataset = drug_dataset.map(compute_review_length)\n",
        "\n",
        "\n",
        "# or alternative way to add new columns to a dataset is with the Dataset.add_column() function."
      ],
      "metadata": {
        "id": "BMux0SJZAR8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the first training example\n",
        "drug_dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKmaEkTQdSvA",
        "outputId": "947aed53-1259-40fb-ea6b-a85d7016a830"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'patient_id': 206461,\n",
              " 'drugName': 'Valsartan',\n",
              " 'condition': 'Left Ventricular Dysfunction',\n",
              " 'review': '\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"',\n",
              " 'rating': 9.0,\n",
              " 'date': 'May 20, 2012',\n",
              " 'usefulCount': 27,\n",
              " 'review_length': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_dataset[\"train\"].sort(\"review_length\")[:3]"
      ],
      "metadata": {
        "id": "0e6jRnK0A3pM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3e7c22-04e7-4a7a-cc2c-37dc38e65d90"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'patient_id': [111469, 13653, 53602],\n",
              " 'drugName': ['Ledipasvir / sofosbuvir',\n",
              "  'Amphetamine / dextroamphetamine',\n",
              "  'Alesse'],\n",
              " 'condition': ['Hepatitis C', 'ADHD', 'Birth Control'],\n",
              " 'review': ['\"Headache\"', '\"Great\"', '\"Awesome\"'],\n",
              " 'rating': [10.0, 10.0, 10.0],\n",
              " 'date': ['February 3, 2015', 'October 20, 2009', 'November 23, 2015'],\n",
              " 'usefulCount': [41, 3, 0],\n",
              " 'review_length': [1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_dataset = drug_dataset.filter(lambda x: x[\"review_length\"] > 30) # max length?\n"
      ],
      "metadata": {
        "id": "47O3cCBbBKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(drug_dataset.num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr2RmZ8Gfi3z",
        "outputId": "d503898f-c06a-41f5-f526-af57474f055b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 138514, 'test': 46108}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "\n",
        "text = \"I&#039;m a transformer called BERT\"\n",
        "html.unescape(text)\n",
        "drug_dataset = drug_dataset.map(lambda x: {\"review\": html.unescape(x[\"review\"])})\n",
        "\n",
        "# or batched\n",
        "new_drug_dataset = drug_dataset.map(\n",
        "    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True\n",
        ")"
      ],
      "metadata": {
        "id": "_PNvd9JWCnTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the same instruction with and without batched=True, then try it with a slow tokenizer (add use_fast=False in the AutoTokenizer.from_pretrained() method) so you can see what numbers you get on your hardware."
      ],
      "metadata": {
        "id": "VKHtgUTZDg8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_drug_dataset = drug_dataset.map(\n",
        "    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=False\n",
        ")"
      ],
      "metadata": {
        "id": "ABvvrinfDh4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"review\"], truncation=True)"
      ],
      "metadata": {
        "id": "rXf5PowXJkWh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZhPmI1nJo6t",
        "outputId": "66b0739b-82d9-45bc-cea7-4f3041e81498"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 28.4 ms, sys: 3.93 ms, total: 32.3 ms\n",
            "Wall time: 70.9 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE5_g39QKAm7",
        "outputId": "afa9181b-d930-4e91-e25a-ca2bcbfd33ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.5 ms, sys: 1.97 ms, total: 24.4 ms\n",
            "Wall time: 25.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try with slow tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"review\"], truncation=True)"
      ],
      "metadata": {
        "id": "02cUPyRSKe7c"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyVjDgpWKwnb",
        "outputId": "e3799647-2e03-40e8-f0fa-f8eb2452490b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 588 ms, sys: 3.02 ms, total: 591 ms\n",
            "Wall time: 610 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0IfKK_FK2Ua",
        "outputId": "c84a30b1-359f-4d2a-e748-157addadf4df"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 381 ms, sys: 4 ms, total: 385 ms\n",
            "Wall time: 385 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
        "\n",
        "\n",
        "def slow_tokenize_function(examples):\n",
        "    return slow_tokenizer(examples[\"review\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)"
      ],
      "metadata": {
        "id": "75t3D5yGMdim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSj2hLdORA5l",
        "outputId": "a050a43a-56aa-4e85-b71b-54e3f8fb684f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 918 ms, sys: 16.6 ms, total: 935 ms\n",
            "Wall time: 1.52 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the average rating per drug and store the result in a new Dataset."
      ],
      "metadata": {
        "id": "hGElnWdaRE3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drug_dataset.set_format(\"pandas\")\n",
        "train_df = drug_dataset[\"train\"][:]"
      ],
      "metadata": {
        "id": "v7JWO8qFRFgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_rating = (\n",
        "    train_df.groupby(\"drugName\")[\"rating\"]\n",
        "    .mean()\n",
        "    .to_frame()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"rating\": \"average_rating\"})\n",
        ")\n",
        "display(average_rating.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qarSRXtFRaij",
        "outputId": "01b21c03-411a-40eb-e1f7-f4d81b995a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               drugName  average_rating\n",
              "0             A + D Cracked Skin Relief       10.000000\n",
              "1                            A / B Otic       10.000000\n",
              "2  Abacavir / dolutegravir / lamivudine        8.211538\n",
              "3    Abacavir / lamivudine / zidovudine        9.000000\n",
              "4                             Abatacept        7.157895"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84f048c6-71eb-4e73-9f30-2cbe22c920a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>average_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A + D Cracked Skin Relief</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A / B Otic</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abacavir / dolutegravir / lamivudine</td>\n",
              "      <td>8.211538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abacavir / lamivudine / zidovudine</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abatacept</td>\n",
              "      <td>7.157895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84f048c6-71eb-4e73-9f30-2cbe22c920a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84f048c6-71eb-4e73-9f30-2cbe22c920a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84f048c6-71eb-4e73-9f30-2cbe22c920a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6bb495fe-ac0f-4668-8275-616aa118de74\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bb495fe-ac0f-4668-8275-616aa118de74')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6bb495fe-ac0f-4668-8275-616aa118de74 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(average_rating\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"drugName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A / B Otic\",\n          \"Abatacept\",\n          \"Abacavir / dolutegravir / lamivudine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.218144131448147,\n        \"min\": 7.157894736842105,\n        \"max\": 10.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8.211538461538462,\n          7.157894736842105,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "avrating_dataset = Dataset.from_pandas(average_rating)\n",
        "avrating_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNdbL4pJSK9h",
        "outputId": "80272314-e373-4ee7-d70b-0291e2697532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['drugName', 'average_rating'],\n",
              "    num_rows: 3431\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_dataset.reset_format()"
      ],
      "metadata": {
        "id": "rJ6J8BEwSwRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use the techniques from Chapter 3 to train a classifier that can predict the patient condition based on the drug review.\n",
        "2. Use the summarization pipeline from Chapter 1 to generate summaries of the reviews."
      ],
      "metadata": {
        "id": "-1mwFWAhU3oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://colab.research.google.com/drive/1Zr0_bBFcAcKtQoVNQJk6OD7Gs30N89sQ"
      ],
      "metadata": {
        "id": "Ds1UOSi_U4_S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}