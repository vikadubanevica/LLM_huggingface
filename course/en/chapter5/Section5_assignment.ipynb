{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBna8jyeXGhD"
      },
      "source": [
        "# Chapter 5 assignments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Use the techniques from Chapter 3 to train a classifier that can predict the patient condition based on the drug review.\n",
        "\n",
        "2.   Use the summarization pipeline from Chapter 1 to generate summaries of the reviews.\n",
        "\n"
      ],
      "metadata": {
        "id": "ndIRkWxBiqOD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e5da80f"
      },
      "source": [
        "# from tqdm.auto import tqdm - removed as causing issues for Github to display notebooks."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7svG1VEZuJCK",
        "outputId": "018d4efa-07b7-4602-e6bc-935a5a92cfc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
        "!unzip drugsCom_raw.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh8eewhZzXHk",
        "outputId": "4b13756a-503f-4bec-9172-d61ffdb4802d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-19 13:55:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip        [     <=>            ]  41.00M  25.5MB/s    in 1.6s    \n",
            "\n",
            "2026-01-19 13:55:28 (25.5 MB/s) - ‘drugsCom_raw.zip’ saved [42989872]\n",
            "\n",
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbe6b2ce",
        "outputId": "f7fcecc6-4063-4630-c346-0733eccbd591"
      },
      "source": [
        "import html\n",
        "from datasets import load_dataset, DownloadConfig, disable_progress_bar\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "disable_progress_bar()\n",
        "\n",
        "download_config = DownloadConfig(disable_tqdm=True)\n",
        "\n",
        "data_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\n",
        "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\", download_config=download_config)\n",
        "drug_dataset = drug_dataset.rename_column(\n",
        "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\")\n",
        "drug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)\n",
        "\n",
        "def lowercase_condition(example):\n",
        "    return {\"condition\": example[\"condition\"].lower()}\n",
        "drug_dataset = drug_dataset.map(lowercase_condition)\n",
        "\n",
        "# Applying HTML unescaping to the Review column\n",
        "drug_dataset = drug_dataset.map(\n",
        "    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True)\n",
        "\n",
        "# Collecting all unique conditions\n",
        "all_conditions = set()\n",
        "for split_name in drug_dataset.keys():\n",
        "    all_conditions.update(drug_dataset[split_name].unique(\"condition\"))\n",
        "\n",
        "# Sprting a list to ensure consistent label assignments\n",
        "unique_conditions = sorted(list(all_conditions))\n",
        "\n",
        "label_to_id = {condition: i for i, condition in enumerate(unique_conditions)}\n",
        "id_to_label = {i: condition for i, condition in enumerate(unique_conditions)}\n",
        "\n",
        "def convert_condition_to_labels(example):\n",
        "    example[\"labels\"] = label_to_id[example[\"condition\"]]\n",
        "    return example\n",
        "\n",
        "# Applying mapping to create the 'labels' column and then removing the original 'condition' column\n",
        "drug_dataset = drug_dataset.map(convert_condition_to_labels)\n",
        "drug_dataset = drug_dataset.remove_columns([\"condition\"])\n",
        "\n",
        "# Reducing the number of samples for each split (5% of original)\n",
        "for split_name in drug_dataset.keys():\n",
        "    original_size = len(drug_dataset[split_name])\n",
        "    sample_size = int(original_size * 0.05)\n",
        "    if sample_size == 0 and original_size > 0:\n",
        "        sample_size = 1\n",
        "    # Randomly sample the dataset.\n",
        "    drug_dataset[split_name] = drug_dataset[split_name].shuffle(seed=42).select(range(sample_size))\n",
        "print(f\"Dataset reduced to 5%. New sizes: {{train: {len(drug_dataset['train'])}, test: {len(drug_dataset['test'])}}}\")\n",
        "\n",
        "# Verifying the mapping and new column\n",
        "print(f\"Number of unique labels: {len(unique_conditions)}\")\n",
        "print(f\"Example label mapping: {list(label_to_id.items())[:5]}\")\n",
        "print(drug_dataset[\"train\"].features)\n",
        "\n",
        "# Tokenizing the dataset after all other transformations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"review\"], truncation=True)\n",
        "tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Creating validation split\n",
        "if \"validation\" not in tokenized_dataset.keys():\n",
        "    train_test_split_dataset = tokenized_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "    tokenized_dataset[\"train\"] = train_test_split_dataset[\"train\"]\n",
        "    tokenized_dataset[\"validation\"] = train_test_split_dataset[\"test\"]\n",
        "\n",
        "# removing extraneous columns that are not model inputs or labels from the tokenized_dataset\n",
        "columns_to_remove = [col for col in tokenized_dataset[\"train\"].column_names if col not in [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"]]\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)\n",
        "\n",
        "# Setting the format to 'torch' after all necessary columns are removed\n",
        "tokenized_dataset.set_format(\"torch\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset reduced to 5%. New sizes: {train: 8019, test: 2673}\n",
            "Number of unique labels: 916\n",
            "Example label mapping: [('0</span> users found this comment helpful.', 0), ('100</span> users found this comment helpful.', 1), ('105</span> users found this comment helpful.', 2), ('10</span> users found this comment helpful.', 3), ('110</span> users found this comment helpful.', 4)]\n",
            "{'patient_id': Value('int64'), 'drugName': Value('string'), 'review': Value('string'), 'rating': Value('float64'), 'date': Value('string'), 'usefulCount': Value('int64'), 'labels': Value('int64')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8212009",
        "outputId": "b0b36d71-99ff-4778-cf85-62db37fa0dde"
      },
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
        "from torch.optim import AdamW\n",
        "\n",
        "accelerator = Accelerator()\n",
        "\n",
        "checkpoint = \"bert-base-cased\"\n",
        "\n",
        "# Dynamically determining num_labels from the unique_conditions found earlier\n",
        "# Ensuring id_to_label and label_to_id are available from previous steps\n",
        "num_labels = len(id_to_label)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint, num_labels=num_labels, id2label=id_to_label, label2id=label_to_id\n",
        ")\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
        "    train_dataloader, eval_dataloader, model, optimizer\n",
        ")\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dl)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dl:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p-_v1oMP8B2W",
        "outputId": "54bf4872-a5b0-497e-864d-377c24218c79"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the metric for multi-class classification\n",
        "# Using 'f1' with 'average=\"weighted\"' for multi-class problem.\n",
        "metric = evaluate.load(\"f1\")\n",
        "\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    # Move batch to device\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # batch of predictions and references to the metric\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "# Compute the final metric\n",
        "metric.compute(average=\"weighted\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vcEGJtE6Twf",
        "outputId": "fc3faec7-b02c-47a7-a027-a994b678f1f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.41851862592985506}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on a 5% subset of dataset, model could obtain almost 50% F1 score => result is good enough."
      ],
      "metadata": {
        "id": "HP0-8-C_85zN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uXn6g5VpD0XD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization part"
      ],
      "metadata": {
        "id": "svrkHjfMDOjc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1d52967"
      },
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
        "!unzip drugsCom_raw.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JsTTK4b_P03",
        "outputId": "7df7a486-057f-43b5-8459-a2b4f9d0d285"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-19 14:49:18--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘drugsCom_raw.zip.3’\n",
            "\n",
            "drugsCom_raw.zip.3      [       <=>          ]  41.00M  20.4MB/s    in 2.0s    \n",
            "\n",
            "2026-01-19 14:49:20 (20.4 MB/s) - ‘drugsCom_raw.zip.3’ saved [42989872]\n",
            "\n",
            "Archive:  drugsCom_raw.zip\n",
            "replace drugsComTest_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "replace drugsComTrain_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "\n",
        "data_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\n",
        "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")\n",
        "drug_dataset = drug_dataset.rename_column(\n",
        "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\")\n",
        "drug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)\n",
        "\n",
        "# Applying HTML unescaping directly to the drug_dataset's review column\n",
        "drug_dataset = drug_dataset.map(\n",
        "    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True)\n"
      ],
      "metadata": {
        "id": "XTHNHOvi_U79"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataset of only reviews\n",
        "drug_dataset_reviews = drug_dataset[\"train\"][\"review\"]"
      ],
      "metadata": {
        "id": "dEqYuNgd_5-I"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking review text\n",
        "drug_dataset_reviews[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "sqUsJhYTBlS5",
        "outputId": "f9c784a6-b9a4-47da-b19d-a2cd9aa43090"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"My son is halfway through his fourth week of Intuniv. We became concerned when he began this last week, when he started taking the highest dose he will be on. For two days, he could hardly get out of bed, was very cranky, and slept for nearly 8 hours on a drive home from school vacation (very unusual for him.) I called his doctor on Monday morning and she said to stick it out a few days. See how he did at school, and with getting up in the morning. The last two days have been problem free. He is MUCH more agreeable than ever. He is less emotional (a good thing), less cranky. He is remembering all the things he should. Overall his behavior is better. \\r\\nWe have tried many different medications and so far this is the most effective.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# checking pipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "synthesized_review = summarizer(drug_dataset_reviews[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNNAqzJE-DWR",
        "outputId": "3c08e60d-c973-4236-bb8f-14231d3c0cb2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e952a86",
        "outputId": "66b5695c-8484-42f5-9403-04cf9e3f77ff"
      },
      "source": [
        "# running pipeline on 5 entries\n",
        "summaries = summarizer(drug_dataset_reviews[:5])\n",
        "for i, summary in enumerate(summaries):\n",
        "    print(f\"--- Review {i+1} ---\")\n",
        "    print(f\"Original: {drug_dataset_reviews[i]}\")\n",
        "    print(f\"Summary: {summary['summary_text']}\\n\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 142, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
            "Your max_length is set to 142, but your input_length is only 110. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Review 1 ---\n",
            "Original: \"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"\n",
            "Summary:  \"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\" \"It's a combination of bystolic . 5mg and fish oil,\" she says of her anti-depressants . \"I take it with no side effects,\" she said of taking it with fish oil .\n",
            "\n",
            "--- Review 2 ---\n",
            "Original: \"My son is halfway through his fourth week of Intuniv. We became concerned when he began this last week, when he started taking the highest dose he will be on. For two days, he could hardly get out of bed, was very cranky, and slept for nearly 8 hours on a drive home from school vacation (very unusual for him.) I called his doctor on Monday morning and she said to stick it out a few days. See how he did at school, and with getting up in the morning. The last two days have been problem free. He is MUCH more agreeable than ever. He is less emotional (a good thing), less cranky. He is remembering all the things he should. Overall his behavior is better. \r\n",
            "We have tried many different medications and so far this is the most effective.\"\n",
            "Summary:  \"My son is halfway through his fourth week of Intuniv.com . We became concerned when he began this last week, when he started taking the highest dose he will be on . For two days, he could hardly get out of bed, was very cranky, and slept for nearly 8 hours on a drive home from school vacation .\n",
            "\n",
            "--- Review 3 ---\n",
            "Original: \"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects. But it contained hormone gestodene, which is not available in US, so I switched to Lybrel, because the ingredients are similar. When my other pills ended, I started Lybrel immediately, on my first day of period, as the instructions said. And the period lasted for two weeks. When taking the second pack- same two weeks. And now, with third pack things got even worse- my third period lasted for two weeks and now it's the end of the third week- I still have daily brown discharge.\r\n",
            "The positive side is that I didn't have any other side effects. The idea of being period free was so tempting... Alas.\"\n",
            "Summary:  Lybrel contains hormone gestodene, which is not available in US, so I switched to it . The idea of being period free was so tempting... Alas, it's the end of the third week- I still have daily brown discharge . The positive side is that I didn't have any other side effects .\n",
            "\n",
            "--- Review 4 ---\n",
            "Original: \"This is my first time using any form of birth control. I'm glad I went with the patch, I have been on it for 8 months. At first It decreased my libido but that subsided. The only downside is that it made my periods longer (5-6 days to be exact) I used to only have periods for 3-4 days max also made my cramps intense for the first two days of my period, I never had cramps before using birth control. Other than that in happy with the patch\"\n",
            "Summary:  \"This is my first time using any form of birth control. I'm glad I went with the patch, I have been on it for 8 months. At first It decreased my libido but that subsided. The only downside is that it made my periods longer (5-6 days to be exact) I used to only have periods for 3-4 days max .\n",
            "\n",
            "--- Review 5 ---\n",
            "Original: \"Suboxone has completely turned my life around.  I feel healthier, I'm excelling at my job and I always have money in my pocket and my savings account.  I had none of those before Suboxone and spent years abusing oxycontin.  My paycheck was already spent by the time I got it and I started resorting to scheming and stealing to fund my addiction.  All that is history.  If you're ready to stop, there's a good chance that suboxone will put you on the path of great life again.  I have found the side-effects to be minimal compared to oxycontin.  I'm actually sleeping better.   Slight constipation is about it for me.  It truly is amazing. The cost pales in comparison to what I spent on oxycontin.\"\n",
            "Summary:  \"Suboxone has completely turned my life around.  I feel healthier, I'm excelling at my job and I always have money in my pocket and my savings account\" \"I have found the side-effects to be minimal compared to oxycontin.  Slight constipation is about it for me.  It truly is amazing. The cost pales in comparison to what I spent on oxycontin.\"\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}